Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: false
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: null
  results_file: out.txt
  root_path: ''
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "default_optimizer")'
  buffer_has_batchdim: false
  save_output: false
  output_file: out.pkl
  return_optimized_model: false
model:
  name: resnet2b
  path: models/cifar10_resnet/resnet2b.pth
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: none
  onnx_vnnlib_joint_optimization_flags: none
  check_optmized: false
  flatten_final_output: false
  optimize_graph: null
  with_jacobian: false
data:
  start: 0
  end: 100
  select_instance: null
  num_outputs: 10
  mean: [0.4914, 0.4822, 0.4465]
  std: [0.2471, 0.2435, 0.2616]
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: 0.00784313725490196
  epsilon_min: 0.0
  vnnlib_path: null
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 2048
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  optimize_disjuncts_separately: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
    relu_option: adaptive
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    disable_optimization: []
  invprop:
    apply_output_constraints_to: []
    tighten_input_bounds: false
    best_of_oc_and_no_oc: false
    directly_optimize: []
    oc_lr: 0.1
    share_gammas: false
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
    reset_threshold: 1.0
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: false
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 120
  timeout_scale: 1
  max_iterations: -1
  override_timeout: null
  get_upper_bound: false
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      use_min: false
      loose_tanh_threshold: null
      dynamic_bbps: false
      dynamic_options: [uniform, three_left, three_right]
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_iters: 1000000000.0
      bf_batch_size: 100000
      bf_zero_crossing_score: false
      touch_zero_score: 0
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
      sb_coeff_thresh: 0.001
      sort_index: null
      sort_descending: true
      show_progress: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 30
  pgd_batch_size: 100000000
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_alpha_scale: false
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: default_adv_saver
  early_stop_condition: default_early_stop_condition
  adv_example_finalizer: default_adv_example_finalizer
  pgd_loss: default_pgd_loss
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: attack_with_general_specs
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0
  print_verbose_decisions: false

Experiments at Sat Jul  6 21:25:32 2024 on abhijit-H81M-S2PV
CResNet5(
  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (shortcut): Sequential(
        (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(2, 2))
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (shortcut): Sequential()
    )
  )
  (linear1): Linear(in_features=1024, out_features=100, bias=True)
  (linear2): Linear(in_features=100, out_features=10, bias=True)
)
Parameters:
  conv1.weight: shape torch.Size([8, 3, 3, 3])
  conv1.bias: shape torch.Size([8])
  layer1.0.conv1.weight: shape torch.Size([16, 8, 3, 3])
  layer1.0.conv1.bias: shape torch.Size([16])
  layer1.0.conv2.weight: shape torch.Size([16, 16, 3, 3])
  layer1.0.conv2.bias: shape torch.Size([16])
  layer1.0.shortcut.0.weight: shape torch.Size([16, 8, 1, 1])
  layer1.0.shortcut.0.bias: shape torch.Size([16])
  layer1.1.conv1.weight: shape torch.Size([16, 16, 3, 3])
  layer1.1.conv1.bias: shape torch.Size([16])
  layer1.1.conv2.weight: shape torch.Size([16, 16, 3, 3])
  layer1.1.conv2.bias: shape torch.Size([16])
  linear1.weight: shape torch.Size([100, 1024])
  linear1.bias: shape torch.Size([100])
  linear2.weight: shape torch.Size([10, 100])
  linear2.bias: shape torch.Size([10])
Trying generic MNIST/CIFAR data loader.
Files already downloaded and verified
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Attack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.008052527904510498, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[-1.19091558, -0.50774616, -0.05718238,  2.23404956, -0.64370054,
          2.38971519,  1.96902382, -1.46069169, -0.98059338, -1.75199282]])
Clean prediction incorrect, attack skipped.
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-1.19091547, -0.50774592, -0.05718319,  2.23405004, -0.64370078,
           2.38971567,  1.96902335, -1.46069157, -0.98059326, -1.75199282],
         [-1.19091547, -0.50774592, -0.05718319,  2.23405004, -0.64370078,
           2.38971567,  1.96902335, -1.46069157, -0.98059326, -1.75199282]]])
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 3.42496538,  2.74179602,  2.29123330,  2.87775087, -0.15566564,
           0.26502669,  3.69474173,  3.21464324,  3.98604226]]])
number of violation:  1
Result: unsafe-pgd in 0.0676 seconds

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 1, vnnlib ID: 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Attack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.008052505552768707, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 3.02953815,  4.21952534, -2.03169966, -1.62848067, -1.60506845,
         -4.36937809, -2.96140265, -3.56549168,  6.42298174,  2.48937225]])
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 2.94738817,  4.78012323, -2.14865780, -1.69613338, -1.80961871,
          -4.40058184, -3.01473784, -3.61580968,  6.10779095,  2.85013866],
         [ 2.94738817,  4.78012323, -2.14865780, -1.69613338, -1.80961871,
          -4.40058184, -3.01473784, -3.61580968,  6.10779095,  2.85013866]]])
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 3.16040277,  1.32766771,  8.25644875,  7.80392456,  7.91740990,
          10.50837326,  9.12252903,  9.72360039,  3.25765181]]])
number of violation:  0
Attack finished in 5.3030 seconds.
PGD attack failed
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[], perturbed=True)
  (/1): BoundParams(name=/1, inputs=[], perturbed=False)
  (/2): BoundParams(name=/2, inputs=[], perturbed=False)
  (/3): BoundParams(name=/3, inputs=[], perturbed=False)
  (/4): BoundParams(name=/4, inputs=[], perturbed=False)
  (/5): BoundParams(name=/5, inputs=[], perturbed=False)
  (/6): BoundParams(name=/6, inputs=[], perturbed=False)
  (/7): BoundParams(name=/7, inputs=[], perturbed=False)
  (/8): BoundParams(name=/8, inputs=[], perturbed=False)
  (/9): BoundParams(name=/9, inputs=[], perturbed=False)
  (/10): BoundParams(name=/10, inputs=[], perturbed=False)
  (/11): BoundParams(name=/11, inputs=[], perturbed=False)
  (/12): BoundParams(name=/12, inputs=[], perturbed=False)
  (/13): BoundParams(name=/13, inputs=[], perturbed=False)
  (/14): BoundParams(name=/14, inputs=[], perturbed=False)
  (/15): BoundParams(name=/15, inputs=[], perturbed=False)
  (/16): BoundParams(name=/16, inputs=[], perturbed=False)
  (/17): BoundConv(name=/17, inputs=[/input.1, /1, /2], perturbed=True)
  (/input): BoundRelu(name=/input, inputs=[/17], perturbed=True)
  (/19): BoundConv(name=/19, inputs=[/input, /3, /4], perturbed=True)
  (/input.4): BoundRelu(name=/input.4, inputs=[/19], perturbed=True)
  (/21): BoundConv(name=/21, inputs=[/input.4, /5, /6], perturbed=True)
  (/22): BoundConv(name=/22, inputs=[/input, /7, /8], perturbed=True)
  (/23): BoundAdd(name=/23, inputs=[/21, /22], perturbed=True)
  (/input.8): BoundRelu(name=/input.8, inputs=[/23], perturbed=True)
  (/25): BoundConv(name=/25, inputs=[/input.8, /9, /10], perturbed=True)
  (/input.12): BoundRelu(name=/input.12, inputs=[/25], perturbed=True)
  (/27): BoundConv(name=/27, inputs=[/input.12, /11, /12], perturbed=True)
  (/28): BoundAdd(name=/28, inputs=[/27, /input.8], perturbed=True)
  (/29): BoundRelu(name=/29, inputs=[/28], perturbed=True)
  (/30): BoundShape(name=/30, inputs=[/29], perturbed=False)
  (/31): BoundConstant(name=/31, value=0)
  (/32): BoundGather(name=/32, inputs=[/30, /31], perturbed=False)
  (/33): BoundConstant(name=/33, value=-1)
  (/34): BoundConstant(name=/34, value=tensor([0]))
  (/35): BoundUnsqueeze(name=/35, inputs=[/32, /34], perturbed=False)
  (/36): BoundConstant(name=/36, value=tensor([0]))
  (/37): BoundUnsqueeze(name=/37, inputs=[/33, /36], perturbed=False)
  (/38): BoundConcat(name=/38, inputs=[/35, /37], perturbed=False)
  (/39): BoundReshape(name=/39, inputs=[/29, /38], perturbed=True)
  (/40): BoundLinear(name=/40, inputs=[/39, /13, /14], perturbed=True)
  (/41): BoundRelu(name=/41, inputs=[/40], perturbed=True)
  (/42): BoundLinear(name=/42, inputs=[/41, /15, /16], perturbed=True)
)
Original output: tensor([[ 3.02953815,  4.21952534, -2.03169966, -1.62848067, -1.60506845,
         -4.36937809, -2.96140265, -3.56549168,  6.42298174,  2.48937225]])
Split layers:
  BoundConv(name=/17, inputs=[/input.1, /1, /2], perturbed=True): [(BoundRelu(name=/input, inputs=[/17], perturbed=True), 0)]
  BoundConv(name=/19, inputs=[/input, /3, /4], perturbed=True): [(BoundRelu(name=/input.4, inputs=[/19], perturbed=True), 0)]
  BoundAdd(name=/23, inputs=[/21, /22], perturbed=True): [(BoundRelu(name=/input.8, inputs=[/23], perturbed=True), 0)]
  BoundConv(name=/25, inputs=[/input.8, /9, /10], perturbed=True): [(BoundRelu(name=/input.12, inputs=[/25], perturbed=True), 0)]
  BoundAdd(name=/28, inputs=[/27, /input.8], perturbed=True): [(BoundRelu(name=/29, inputs=[/28], perturbed=True), 0)]
  BoundLinear(name=/40, inputs=[/39, /13, /14], perturbed=True): [(BoundRelu(name=/41, inputs=[/40], perturbed=True), 0)]
Nonlinear functions:
   BoundRelu(name=/input, inputs=[/17], perturbed=True)
   BoundRelu(name=/input.4, inputs=[/19], perturbed=True)
   BoundRelu(name=/input.8, inputs=[/23], perturbed=True)
   BoundRelu(name=/input.12, inputs=[/25], perturbed=True)
   BoundRelu(name=/29, inputs=[/28], perturbed=True)
   BoundRelu(name=/41, inputs=[/40], perturbed=True)
layer /input using sparse-features alpha with shape [158]; unstable size 158; total size 2048 ([1, 8, 16, 16])
layer /input start_node /19 using sparse-spec alpha [2, 168, 1, 158] with unstable size 167 total_size 1024 output_shape (16, 8, 8)
layer /input start_node /23 using sparse-spec alpha [2, 102, 1, 158] with unstable size 101 total_size 1024 output_shape (16, 8, 8)
layer /input start_node /25 using sparse-spec alpha [2, 121, 1, 158] with unstable size 120 total_size 1024 output_shape (16, 8, 8)
layer /input start_node /28 using sparse-spec alpha [2, 248, 1, 158] with unstable size 247 total_size 1024 output_shape (16, 8, 8)
layer /input start_node /40 using sparse-spec alpha [2, 33, 1, 158] with unstable size 32 total_size 100 output_shape torch.Size([100])
layer /input start_node /42 using full alpha [2, 9, 1, 158] with unstable size None total_size 9 output_shape 9
layer /input.4 using sparse-features alpha with shape [167]; unstable size 167; total size 1024 ([1, 16, 8, 8])
layer /input.4 start_node /23 using sparse-spec alpha [2, 102, 1, 167] with unstable size 101 total_size 1024 output_shape (16, 8, 8)
layer /input.4 start_node /25 using sparse-spec alpha [2, 121, 1, 167] with unstable size 120 total_size 1024 output_shape (16, 8, 8)
layer /input.4 start_node /28 using sparse-spec alpha [2, 248, 1, 167] with unstable size 247 total_size 1024 output_shape (16, 8, 8)
layer /input.4 start_node /40 using sparse-spec alpha [2, 33, 1, 167] with unstable size 32 total_size 100 output_shape torch.Size([100])
layer /input.4 start_node /42 using full alpha [2, 9, 1, 167] with unstable size None total_size 9 output_shape 9
layer /input.8 using sparse-features alpha with shape [101]; unstable size 101; total size 1024 ([1, 16, 8, 8])
layer /input.8 start_node /25 using sparse-spec alpha [2, 121, 1, 101] with unstable size 120 total_size 1024 output_shape (16, 8, 8)
layer /input.8 start_node /28 using sparse-spec alpha [2, 248, 1, 101] with unstable size 247 total_size 1024 output_shape (16, 8, 8)
layer /input.8 start_node /40 using sparse-spec alpha [2, 33, 1, 101] with unstable size 32 total_size 100 output_shape torch.Size([100])
layer /input.8 start_node /42 using full alpha [2, 9, 1, 101] with unstable size None total_size 9 output_shape 9
layer /input.12 using sparse-features alpha with shape [120]; unstable size 120; total size 1024 ([1, 16, 8, 8])
layer /input.12 start_node /28 using sparse-spec alpha [2, 248, 1, 120] with unstable size 247 total_size 1024 output_shape (16, 8, 8)
layer /input.12 start_node /40 using sparse-spec alpha [2, 33, 1, 120] with unstable size 32 total_size 100 output_shape torch.Size([100])
layer /input.12 start_node /42 using full alpha [2, 9, 1, 120] with unstable size None total_size 9 output_shape 9
layer /29 using sparse-features alpha with shape [247]; unstable size 247; total size 1024 ([1, 16, 8, 8])
layer /29 start_node /40 using sparse-spec alpha [2, 33, 1, 247] with unstable size 32 total_size 100 output_shape torch.Size([100])
layer /29 start_node /42 using full alpha [2, 9, 1, 247] with unstable size None total_size 9 output_shape 9
layer /41 using sparse-features alpha with shape [32]; unstable size 32; total size 100 ([1, 100])
layer /41 start_node /42 using full alpha [2, 9, 1, 32] with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.45695734, -0.51258337,  6.35851669,  6.13861847,  6.03921032,
          8.38362503,  7.31514931,  7.53226233,  1.30834103]]) None
best_l after optimization: 45.46355056762695
alpha/beta optimization time: 163.99794244766235
initial alpha-crown bounds: tensor([[ 1.62279153, -0.32243747,  6.51509809,  6.26511765,  6.18413734,
          8.56207657,  7.44294930,  7.70946121,  1.48435521]])
Worst class: (+ rhs) -0.32243746519088745
Total VNNLIB file length: 9, max property batch size: 1, total number of batches: 9
lA shape: [torch.Size([9, 1, 8, 16, 16]), torch.Size([9, 1, 16, 8, 8]), torch.Size([9, 1, 16, 8, 8]), torch.Size([9, 1, 16, 8, 8]), torch.Size([9, 1, 16, 8, 8]), torch.Size([9, 1, 100])]

Properties batch 0, size 1
Remaining timeout: -49.80791664123535
